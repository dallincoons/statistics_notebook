---
title: "Residuals"
output: 
  html_document:
    theme: cerulean
    code_folding: hide
---

```{r, include=FALSE}
library(ggplot2)
library(readr)
library(tidyverse)
library(mosaic)
```

```{r}

raw_laptops <- read.csv('../Data/laptops.csv')

laptops <- raw_laptops %>% 
  mutate(
    numeric_ram = parse_number(as.character(Ram)),
    numeric_weight = parse_number(as.character(Weight))
  ) %>% 
  filter(numeric_ram < 60)
ram.lm <- lm(Price_euros ~ numeric_ram, data = laptops)
```

The regression line, or $\hat{Y}_i$, represents the rate of change in the average of Y as X changes, so for every X value, there is a corresponding average for Y which changes as X changes. 

For example, the regression below represents the change in the average price (Y) of a laptop as Ram (X) increases. If we look at laptops with 4 gigabytes of RAM, the placement of the line represents the average price value for laptops with 4 gigabytes of RAM.

```{r}

ggplot(laptops, aes(x = numeric_ram, y = Price_euros)) +
  geom_point(aes(color="steelblue"), show.legend = FALSE) +
  geom_point(aes(x=4, y=200, col="red"), size = 2.5, show.legend = FALSE) +
  geom_point(aes(x=4, y=2000, col="green",), size = 2.5, show.legend = FALSE) +
  scale_x_continuous(breaks = seq(2, 32, by = 2)) +
  geom_abline(slope = ram.lm$coefficients[2], intercept=ram.lm$coefficients[1], color="gray") +
  labs(y = "Price (Euros)", x="RAM (Gigabytes)") +
  theme_bw()

```

Obviously, not all laptops with 4 gigabytes of RAM have the same price. Some are above the average, and some below. The numerical representation of how far above or below average the laptop is at that particular point is referred to as a residual. 

For example, based on the data we are using for the regression, the average price for a 4 gigabyte laptop is estimated to be about 676 dollars. If a 4 gigabyte laptop costed 200 dollars, it's residual value would be -476 (represented by a green dot), meaning it's 476 dollars below average for laptops with 4 gigabytes of RAM. Similarly, if a 4 gigabyte laptop costs 2000 dollars, it's residual is 1324 (represented as a red dot), or 1324 dollars above average. 

In this way, if you know the number of gigabytes of RAM your computer has and the amount you paid, it's possible to compute a residual which will inform you whether you paid more or less than average.

### SSTO, SSR, and SSE

In order to determine how well the regression line "explains" the data, or how well the data "fits" the regression line, it's very helpful to look at the different measures of variance.

The average laptop price is plotted with the red line. If we measure the difference of each point from the red line, square each difference and add them up, this will give us SSTO or the Total Sum of Squares.

```{r}

ggplot(laptops, aes(x = 0, y = Price_euros)) +
  geom_point(color="steelblue") +
  geom_hline(yintercept=mean(laptops$Price_euros), color="red", linetype="dashed") +
  labs(y = "Price (Euros)", x="RAM (Gigabytes)", main="Price mean shown in red") +
  theme_bw()
```

By way of example, the mean of the price is about 1123.69. If a laptop is priced at 3000, it deviates from the mean by about 877 dollars (shown by a red dot). We would then square 877 and add it to all the other 'squared differences'. The result will give us an idea of the total deviation from the mean of Y.


```{r}

ggplot(laptops, aes(x = numeric_ram, y = Price_euros)) +
  geom_point(color="steelblue") +
  geom_point(aes(x=4, y=2000, col="firebrick"), size = 2.5, show.legend = FALSE) +
  geom_hline(yintercept=mean(laptops$Price_euros), color="red", linetype="dashed") +
  labs(y = "Price (Euros)", x="RAM (Gigabytes)", main="Price mean shown in red") +
  theme_bw()

```

If we denoted each point as ($Y_i$) and the mean, or the red line as ($\bar{Y}$), this could be shown using the following formula:

$$
SSTO = \sum_{i=1}^n (Y_i - \bar{Y})^2
$$

SSTO is not terribly helpful to help us determine how well the regression model does to explain the deviation from the mean and ultimately help us make predictions, but we'll see how it is useful when combined with other measurements. Our goal is to find a regression line that the data follows as closely as possible. We want to find a regression model that doesn't have a lot of variance from the regression line.
The lower the variance, the more confident we can be in our model to help us make future predictions.

The next one we'll look at is SSR, or Sum of Squares regression. SSR measures how far the regression line (black line) deviates from Y's mean (red line). For laptops with 4 gigabytes of ram, the estimated price according to the regression is about 676 dollars, while the overall mean price for laptops is about 1123.69. Thus, the deviation would be 447 dollars. SSR is calculated by taking this difference for each value, squaring them, and summing them all together.

```{r}
ggplot(laptops, aes(x = numeric_ram, y = Price_euros)) +
  geom_point(color="steelblue") +
  geom_hline(yintercept=mean(laptops$Price_euros), color="red", linetype="dashed") +
  geom_abline(slope = ram.lm$coefficients[2], intercept=ram.lm$coefficients[1], color="black") +
  labs(y = "Price (Euros)", x="RAM (Gigabytes)", main="Price mean shown in red") +
  theme_bw()
```

Denoting the regression line as $\hat{Y}_i$ gives us the following formula for SSR:

$$
SSR = \sum_{i=1}^n (\hat{Y}_i - \bar{Y})^2
$$

SSE is measured by taking all residuals as discussed in the first section, squaring each one and summing them all together (remember, the residual is calculated as $Y_i - \hat{Y}_i$), giving us the formula:

$$
SSE = \sum_{i=1}^n (Y_i - \hat{Y})^2
$$

```{r}

ggplot(laptops, aes(x = numeric_ram, y = Price_euros)) +
  geom_point(color="steelblue") +
  geom_point(aes(x=4, y=2000, col="firebrick"), show.legend = FALSE) +
  geom_hline(yintercept=mean(laptops$Price_euros), color="red", linetype="dashed") +
  geom_abline(slope = ram.lm$coefficients[2], intercept=ram.lm$coefficients[1], color="red") +
  labs(y = "Price (Euros)", x="RAM (Gigabytes)", main="Price mean shown in red") +
  theme_bw()
```

## R-Squared

All of this leads us to be able to show how well our regression model explains the variation of the data from the mean. $R^2$ is a more intuitive measure of this over the correlation coefficient $r$ because it's simple to see $R^2$ and tell what percentage of the variation is explained by the model, whereas $r$ is a value from -1 to 1 that's not as easy to decipher the meaning.

Another way to put it is if the data follows the regression line perfectly, then everything we see is perfectly explainable and we would see an $R^2$ of 1.

The calculation for this value is

$R^2 = \frac{SSR}{SSTO}$ or $R^2 = 1 - \frac{SSE}{SSTO}$

or in plain english, $R^2$ is $\frac{\text{Variation explained by the regression}}{\text{Total Variation}}$ meaning we want to explain as much of the total variation (SSTO) as possible by our regression. Everything left over is variation that we can't explain with the regression model.

For example, the regression we've been using so far, comparing RAM with price, has an $R^2$ value of 0.5603, meaning that 56 percent of the variance of the Y variable can be explained by the regression model. Comparing weight with price has a lower value of 0.04196, and you can see that the data does not fit very well with the regression:

```{r}

weight.lm <- lm(Price_euros ~ numeric_weight, data = laptops)

ggplot(laptops, aes(x = numeric_weight, y = Price_euros)) +
  geom_point(color="steelblue") +
  geom_abline(slope = weight.lm$coefficients[2], intercept=weight.lm$coefficients[1], color="red") +
  labs(y = "Price (Euros)", x="Weight (Kilograms)") +
  theme_bw()
```

Comparing weight with screen width has the best $R^2$ value yet (0.6844), and the line does seem to do a better job of capturing the relationship between X and Y.

```{r}

inches.lm <- lm(numeric_weight ~ Inches, data = laptops)

ggplot(laptops, aes(x = Inches, y = numeric_weight)) +
  geom_point(color="steelblue") +
  geom_abline(slope = inches.lm$coefficients[2], intercept=inches.lm$coefficients[1], color="red") +
  labs(y = "Inches", x="Weight (Kilograms)") +
  theme_bw()
```
