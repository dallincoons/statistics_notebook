---
title: "House Prices"
output:
 html_document:
    theme: cerulean
    code_folding: hide
---

```{r, include=FALSE, warning=FALSE}
library(tidyverse)
library(pander)
library(scorecard)
library(mosaic)
library(car)
library(DT)

hp <- read_csv("../Data/house_prices/train.csv") %>% 
    mutate(CentralAir2 = ifelse(CentralAir == "Y", 1, 0)) %>% 
    mutate(F1SF = `1stFlrSF`) %>% 
    mutate(F2SF = `2ndFlrSF`)

dt_list <- split_df(hp, ratio = 0.75, seed = 101)

hp <- dt_list$train
    # select(Neighborhood, OverallQual, OverallCond, YearBuilt, YearRemodAdd, ExterQual,
    #           Foundation, BsmtQual, TotalBsmtSF, Heating, CentralAir2, Electrical, '1stFlrSF', '2ndFlrSF', GrLivArea, BsmtHalfBath, FullBath, TotRmsAbvGrd, GarageYrBlt, GarageFinish, GarageCars, GarageArea, SaleCondition, SalePrice)

hp <- as.data.frame(unclass(hp))

hp <- hp %>% select(Neighborhood, OverallQual, BsmtQual, CentralAir2, F1SF, F2SF, FullBath, GarageFinish, GarageCars, SaleCondition, SalePrice)
# pairs(hp)
# pairs(hp %>% select(BsmtHalfBath, FullBath, GarageYrBlt, GarageFinish, GarageCars, GarageArea, SaleCondition, SalePrice))
```

## Background

Given a list of 80 attributes of houses in Ames, Iowa, can we find a model which will allow us to predict the price that the home will sell for?

## {.tabset}

### Model Selection

I narrowed down columns to ones that looked interesting in the pairs plot, and I narrowed it down further after investigating each attribute individually. I removed 'Street' for example, because there were 6 instances of Gravel and 1454 of Paved, so I don't see that there's enough representation from either category to aid the prediction. 

Some attributes like LandCountour just didn't seem to explain SalePrice as well as some of the others, and I want to narrow it down as much as possible so the pairs plot won't melt my computer. I also found that 'quality' attributes were usually accompanied by 'condition' attributes, and that 'quality' generally seemed to explain SalePrice better, so I removed 'conditions' from my pairs plot.

From the inital pairs plot it looked like OverallQual might be a good place to start, and I was happy with the adjusted r-squared value of .6254 as a starting point.

```{r, warning=FALSE}
lm <- lm(SalePrice ~ OverallQual, data = hp)
summary(lm)

pairs(cbind(R=lm$res, fit=lm$fit, hp), pch=16, cex=1, panel=panel.smooth, col.smooth="skyblue4")
```

CentralAir looked like it might be promising, so I added it and while it was significant, it only boosted the adjusted r-squared by .01 so maybe I'll revisit it.

I was curious about FullBath and the interaction with OverallQual which was ok, but in trying a few other things I found that GarageCars was both significant and boosted adjusted r-squared by a full `.1`, so I added that to my model. GarageCars is a quantative variable so that's going to introduce an additional dimension, and it's good to keep in mind that with more dimensions comes a higher difficulty in interpretation.

```{r, warning=FALSE}

lm4 <- lm(SalePrice ~ OverallQual + GarageCars + OverallQual:GarageCars, data = hp)
summary(lm4)
```

After more trial and error of different attributes, I found that adding 1stFlrSF and 2ndFlrSF (quantatative variables) increased adjust r-squared by another .08. However OverallQual then became not significant, so I removed it.

```{r, warning=FALSE}

lm6 <- lm(SalePrice ~ GarageCars + GarageCars:OverallQual + F1SF + F2SF, data = hp)
summary(lm6)
pairs(cbind(R=lm6$res, fit=lm6$fit, hp), pch=16, cex=1, panel=panel.smooth, col.smooth="skyblue4")

b <- coef(lm6)
```

And after trying out more variables, I couldn't get r-squared past ~.8, where it currently sits. The one exception is Neighborhood, which added another .03. However I'm probably going to need to spend my time and energy condensing the 25 unique neighorhoods, so I don't think I'm going to add that variable for this analysis.

After checking the residuals, it looks like there's constant variance and ok linearity with a few outliers which may be affecting the regression. and it we can't say the the data is normal.

My model defined formally is:

$$
Y_i = \beta_0 + \beta_1\underbrace{X_\text{1i}}_\text{Garage Cars} + \beta_2\underbrace{X_\text{2i}}_\text{1st floor Sq ft} + \beta_3\underbrace{X_\text{3i}}_\text{2nd floor Sq Ft} + \beta_4\underbrace{X_\text{1i}X_\text{4i}}_\text{GarageCars:OverallQuality interaction}
$$

## Diagnostics

The diagnostic plots below show a severe outlier in point 985 which is negatively affecting the regression. It has the highest Cook's distance showing that if that point was removed, it would have the biggest affect. It also looks like 393 may be causing issues as well, and to a lesser extent 676. It would make sense to remove points 985 and 393, and possibly 676. 

After removing those points, the adjusted r-squared value increased to .8363. It would be worth it to compare the results from removing outliers to a robust regression model.

```{r, fig.height=3}
par(mfrow=c(1,3))
plot(lm6, which=c(1,4,5))

# lm6.o <- lm(SalePrice ~ GarageCars + GarageCars:OverallQual + F1SF + F2SF, data = hp[c(-985, -676, - 393),])
# 
# summary(lm6.o)
# 
# library(MASS)
# 
# lm6.r <- rlm(SalePrice ~ GarageCars + GarageCars:OverallQual + F1SF + F2SF, data = hp)
# 
# summary(lm6.r)
```

### Model Interpretation

There is some complexity to this model that makes it difficult to interpret, but there are some more obvious aspects which more easily interpretable, which I'll talk about first. According to the F1Sf estimate of my model, for every square footage that is added to the first floor, about 56 dollars is added to the value of the house. Second floor square footage also has value, but not as much as the first floor, with 32 dollars in value added for every square foot on the second floor.

```{r}
b <- coef(lm6)
palette(c("skyblue", "orange", "lightgray"))

## Plot 3

hp2 <- hp %>% 
  mutate(group = case_when(
    (OverallQual == 6 & GarageCars == 1) ~ 1,
    (OverallQual == 8 & GarageCars == 3) ~ 2,
    TRUE ~ 3
  ))

plot(SalePrice ~ F1SF, data = hp2, xlab = "First Floor Square Footage", main="1st Floor Sq Ft = 1163, 2nd Floor Sq Ft = 728", col=group, pch = 16)
OQ = 6; GC = 1; F1 = 1163; F2 = 728;
curve(b[1] + b[2]*GC + b[3]*x + b[4]*F2 + b[5]*OQ*GC, add=T, col="skyblue")
OQ = 8; GC = 3; F1 = 1163; F2 = 728;
curve(b[1] + b[2]*GC + b[3]*x + b[4]*F2 + b[5]*OQ*GC, add=T, col="orange")

legend("topleft", legend=c("Overall Quality 4, Garage Cars 2", "Overall Quality 6, Garage Cars 4"), bty="n", lty=1, col=c("skyblue","orange"), cex=0.8)
```

```{r}

## Plot 4

hp3 <- hp %>% 
  mutate(group = case_when(
    (OverallQual == 6 & GarageCars == 1) ~ 1,
    (OverallQual == 8 & GarageCars == 2) ~ 2,
    TRUE ~ 3
  ))

plot(SalePrice ~ F2SF, data = hp3, xlab = "Second Floor Square Footage", main="1st Floor Sq Ft = 1163, 2nd Floor Sq Ft = 728", col=group, pch = 16)

OQ = 6; GC = 1; F1 = 1163; F2 = 728;
curve(b[1] + b[2]*GC + b[3]*F1 + b[4]*x + b[5]*OQ*GC, add=T, col="skyblue")

OQ = 8; GC = 2; F1 = 1163; F2 = 728;
curve(b[1] + b[2]*GC + b[3]*F1 + b[4]*x + b[5]*OQ*GC, add=T, col="orange")

legend("topleft", legend=c("Overall Quality 6, Garage Cars 4", "Overall Quality 3, Garage Cars 1"), bty="n", lty=1, col=c("skyblue","orange"), cex=0.8)
```

The Overall Quality interaction with GarageCars is a bit more complex. The value that is added when car capacity is added to the garage changes depending on what the Overall Quality rating is. What I found from my model is that if a house has a Quality Rating of 1, then adding a car to the garage would bring down the value by 50,792 dollars. There are no houses with a rating of zero though, at least not in the studied sample. However, even with quality ratings all the way up to 3, adding car capacity to a garage will cause the house to lose value. 

With a rating of 4 the house will simply retain the same value as before (blue line), so residents of those houses should only add car capacity to the garage if they actually have a need for the space.

For houses with quality ratings from 5 to 8, the additional car space will increase the rate of change of the sale price by about 12,700 (orange line). For 'high quality' houses, it might be financially advantageous to add additional car capacity depending on what the costs of the addition itself would be.

```{r}
## Plot 2

hp_gc <- hp %>%  mutate(group = case_when(
    (OverallQual == 4 & GarageCars == 2) ~ 1,
    (OverallQual == 8 & GarageCars == 2) ~ 2,
    TRUE ~ 3
  ))

plot(SalePrice ~ GarageCars, data = hp_gc, col=group, main="1st Floor Sq Ft = 1163, 2nd Floor Sq Ft = 728 ")

OQ = 4; GC = 2; F1 = 1163; F2 = 728;
curve(b[1] + b[2]*x + b[3]*F1 + b[4]*F2 + b[5]*OQ*x, add=T, col="skyblue")

OQ = 8; GC = 2; F1 = 1163; F2 = 728;
curve(b[1] + b[2]*x + b[3]*F1 + b[4]*F2 + b[5]*OQ*x, add=T, col="orange")

legend("topleft", legend=c("Overall Quality 4", "Overall Quality 8"), bty="n", lty=1, col=c("skyblue","orange"), cex=0.8)
```

```{r}
## Plot 1

hp_oq <- hp %>%  mutate(group = case_when(
    (GarageCars == 2) ~ 1,
    (GarageCars == 3) ~ 2,
    TRUE ~ 3
  ))

plot(SalePrice ~ OverallQual, data = hp_oq, col=group, main="1st Floor Sq Ft = 1163, 2nd Floor Sq Ft = 728")

CA = 0; GC = 2; F1 = 1163; F2 = 728;
curve(b[1] + b[2]*GC + b[3]*F1 +b[4]*F2 + b[5]*x*GC, add=T, col="skyblue")

CA = 0; GC = 3; F1 = 1163; F2 = 728;
curve(b[1] + b[2]*GC + b[4]*F1 +b[4]*F2 + b[5]*x*GC, add=T, col="orange")
legend("topleft", legend=c("2 Garage Cars", "4 Garage Cars"), bty="n", lty=1, col=c("skyblue","orange"), cex=0.8)
```

### Validation

```{r, warning=FALSE, include=FALSE}
new_hp <- read_csv("../Data/house_prices/test.csv") %>% 
    mutate(CentralAir2 = ifelse(CentralAir == "Y", 1, 0)) %>% 
    mutate(F1SF = `1stFlrSF`) %>% 
    mutate(F2SF = `2ndFlrSF`)
```

```{r}
validate <- function(lm, data) {
  yh1 <- predict(lm, newdata=data)
  
  ybar <- mean(data$SalePrice)
  
  SSTO <- sum( (data$SalePrice - ybar)^2 )

  SSE <- sum( (data$SalePrice - yh1)^2 )

  rs1 <- 1 - SSE/SSTO

  n <- length(data$SalePrice)
  p <- length(coef(lm))
  
  rsa <- 1 - (n-1)/(n-p)*SSE/SSTO
  
  return(rsa)
}

validate(lm6, dt_list$test)
```

When validating the model, the new adjusted r-squared is .79, which remains about the same as the original adjusted r-squared value. That satisifies me that the model isnâ€™t overfitted to sample I used to build the model from.


