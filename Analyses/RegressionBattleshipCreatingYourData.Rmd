---
title: "Regression Battleship - Creating your Data"
author: "Your Name Here"
output: 
  html_document:
    theme: cerulean
---

## Creating your Data

Remember the rules...

### Rules

1. Your csv must contain 11 columns of data.
    * The first column must be your (1) Y-variable (labeled as "Y").
    * The other ten columns must be (10) X-variables (labeled as "X1", "X2", ... , "X10").
    
2. Your Y-variable (or some transformation of the Y-variable) must have been created from a linear regression model using only X-variables (or transformations of those X-variables) from within your data set.
    * Be very careful with transformations. You must ensure that you do not break the rules of a linear regression if you choose to use transformations.
    * If you choose transformations, only these functions are allowed when transforming X and Y variables: 1/Y^2, 1/Y, log(Y), sqrt(Y), Y^2, Y^3, 1/X^2, 1/X, log(X), sqrt(X), X^2, X^3, X^4, X^5. Don't forget to check Rule #3 carefully if you choose transformations.
    
3. Your sample size must be sufficiently large so that when the true model is fit to your data using lm(...), all p-values of X-variable terms (not including the intercept) found in the summary(...) are significant.


### True Model

Write out your final "true" model in mathematical form. Make sure it matches your code.

$$
  \text{EXAMPLE:} \ Y_i = \beta_0 + \beta_1 X_{4i} + \beta_2 X_{2i} + \beta_3 X_{4i} X_{2i} + \epsilon_i
$$

### The Code to Make the Data

```{r}
set.seed(122) #This ensures the randomness is the "same" everytime if you play the entire R-chunk as one entire piece of code. If you run lines separately, your data might not come out the same every time.

## To begin, decide on your sample size. (You may have to revise it later to ensure all values in your lm(...) are significant.)
  
 n <- 50
  
## Then, create 10 X-variables using functions like rnorm(n, mean, sd), rchisq(n, df), rf(n, df1, df2), rt(n, df), rbeta(n, a, b), runif(n, a, b) or sample(c(1,0), n, replace=TRUE)...

 X1 <- rep(0,n) #replace this
 X2 <- rep(0,n) #replace this
 X3 <- rep(0,n) #replace this
 X4 <- rep(0,n) #replace this
 X5 <- rep(0,n) #replace this
 X6 <- rep(0,n) #replace this
 X7 <- rep(0,n) #replace this
 X8 <- rep(0,n) #replace this
 X9 <- rep(0,n) #replace this
 X10 <- rep(0,n) #replace this
 
## Then, create betas, errors (by choosing sigma), and Y
 
 #beta0 <- ...
 #beta1 <- ...   
 #...
 
 sigma <- 1.72 #change to whatever you want
 

 ################################
 # You CANNOT change this part:
 errors <- rnorm(n, 0, sigma)
 ################################ 
 
 #An example of how to make Y...
 # Y <-  beta0 + beta1*X1 + beta2*X2 + beta3*X4*X2 + errors
 
 Y <- 0 #...edit this code and replace it with your model
 
 # You can include Y' or X' instead of Y or X if you wish.
 # Remember, only these functions are allowed when transforming
 # variables: 1/Y^2, 1/Y, log(Y), sqrt(Y), Y^2, Y^3, 1/X^2, 1/X, log(X), sqrt(X), X^2, X^3, X^4, X^5. 
 #########################################################
 # ILLEGAL: Y = (beta0 + beta1*X5)^2 + epsilon ###########
 #########################################################
 # Legal: sqrt(Y) = beta0 + beta1*X5^2 + epsilon #########
 #########################################################
 # You can only transform individual terms, not groups of terms.
 # And the beta's cannot be part of the transformation.

 
 # Load your data into a data set:
 RBdata <- data.frame(Y, X1, X2, X3, X4, X5, X6, X7, X8, X9, X10)
 
 #Now fit your model to make sure it comes out significant:
 mylm <- lm(Y ~ 0, data=RBdata) #edit this code
 summary(mylm) 
 #all p-values must be significant, except "(Intercept)"

```
  
```{r}
# Once you are ready, run this code to write your data to a csv:
write.csv(RBdata, "RBdata.csv", row.names=FALSE)
# The above code writes the dataset to your "current directory"
# To see where that is, use: getwd() in your Console.
# Find the data set and upload it to I-Learn.
```


 

 